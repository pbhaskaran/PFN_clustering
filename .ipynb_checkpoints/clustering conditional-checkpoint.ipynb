{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79320e42-5b6e-4d43-b9f6-32d8c390e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "import transformer \n",
    "import bar_distribution\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import prior \n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import main\n",
    "import importlib\n",
    "device = torch.device(\"cuda\")\n",
    "importlib.reload(utils)\n",
    "importlib.reload(transformer)\n",
    "importlib.reload(bar_distribution)\n",
    "importlib.reload(main)\n",
    "importlib.reload(prior)\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "#####################################################################################################################################################\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61405435-19a9-4ed2-8443-078133fe1721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: Quadro P1000\n",
      "total params:2114442\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "device = torch.device(\"cuda\")\n",
    "d_model, nhead, nhid, nlayers = 256, 4, 512, 4\n",
    "num_epochs = 1\n",
    "lr = 0.001\n",
    "num_outputs = 10\n",
    "seq_len = 200\n",
    "batch_size = 200\n",
    "in_features = 2\n",
    "noise = False\n",
    "warm_up_epochs = 5\n",
    "std_variation=True\n",
    "model = transformer.Transformer(d_model, nhead, nhid, nlayers,in_features=in_features, buckets_size=num_outputs).to(device)\n",
    "print(f\"total params:{sum(p.numel() for p in model.parameters())}\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = utils.get_cosine_schedule_with_warmup(optimizer, warm_up_epochs, num_epochs)\n",
    "model.criterion = criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32429c1-af89-4ec4-b97a-d63aae0f5543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([186, 200, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m trains\u001b[38;5;241m=\u001b[39m main\u001b[38;5;241m.\u001b[39mtrain(model, criterion, num_epochs, optimizer, scheduler, batch_size,seq_len, in_features, num_classes\u001b[38;5;241m=\u001b[39mnum_outputs)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\TU Delft CSE Masters Y2\\Thesis Projects\\PFN clustering\\main.py:24\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, num_epochs, optimizer, scheduler, batch_size, seq_len, num_features, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     23\u001b[0m batch_cluster_output \u001b[38;5;241m=\u001b[39m batch_cluster_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_cluster_output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28mprint\u001b[39m(targets)\n\u001b[0;32m     25\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(targets\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3new\\envs\\cuda_test\\Lib\\site-packages\\torch\\_tensor.py:523\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    520\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    521\u001b[0m     )\n\u001b[0;32m    522\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[1;32m~\\anaconda3new\\envs\\cuda_test\\Lib\\site-packages\\torch\\_tensor_str.py:708\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    707\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 708\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _str_intern(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n",
      "File \u001b[1;32m~\\anaconda3new\\envs\\cuda_test\\Lib\\site-packages\\torch\\_tensor_str.py:625\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    623\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    624\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m, indent)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    628\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32m~\\anaconda3new\\envs\\cuda_test\\Lib\\site-packages\\torch\\_tensor_str.py:357\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    355\u001b[0m     )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _Formatter(get_summarized_data(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32m~\\anaconda3new\\envs\\cuda_test\\Lib\\site-packages\\torch\\_tensor_str.py:146\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(\n\u001b[1;32m--> 146\u001b[0m         tensor_view, torch\u001b[38;5;241m.\u001b[39misfinite(tensor_view) \u001b[38;5;241m&\u001b[39m tensor_view\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "trains= main.train(model, criterion, num_epochs, optimizer, scheduler, batch_size,seq_len, in_features, num_classes=num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc0b8e-301b-48d6-bf37-34f1f1ae5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.scatter(np.arange(num_epochs), trains, label=\"training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c254d9-662f-4e64-bcc2-941e902a2776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e3313-fbe9-45be-93d9-c6a11670a696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_test",
   "language": "python",
   "name": "cuda_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
